{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analogies_uisng_pretrained_glove.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpe997zoAQ4NlfS7wuAsU1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvircohen0/NLP/blob/main/analogies_uisng_pretrained_glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twGnBoZ2d6T7"
      },
      "source": [
        "## **Download the Stanford Glove vectors file and import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5SjVwHUrVwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b43764-642a-4b6a-bd9d-691d793485f8"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.metrics.pairwise import pairwise_distances\r\n",
        "\r\n",
        "!wget http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\r\n",
        "!unzip '/content/glove.6B.zip'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-03 15:38:10--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  2.01MB/s    in 6m 30s  \n",
            "\n",
            "2021-02-03 15:44:41 (2.11 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  /content/glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqdIHxy-fday"
      },
      "source": [
        "## **Find analogies for three input words**\r\n",
        "\r\n",
        "for example: if the input words are \"king\", \"man\" and \"woman\",\r\n",
        "\r\n",
        "the output should be \"queen\" because:\r\n",
        "\r\n",
        "king - man + woman = queen\r\n",
        "\r\n",
        "king - man = queen - woman"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYdYYjWCQySH"
      },
      "source": [
        "def find_analogies(w1, w2, w3):\r\n",
        "  # check if all the words are in the vocabulary\r\n",
        "  for w in (w1, w2, w3):\r\n",
        "    if w not in word2vec:\r\n",
        "      print(\"%s not in dictionary\" % w)\r\n",
        "      return\r\n",
        "\r\n",
        "  king = word2vec[w1]\r\n",
        "  man = word2vec[w2]\r\n",
        "  woman = word2vec[w3]\r\n",
        "  v0 = king - man + woman\r\n",
        "\r\n",
        "  distances = pairwise_distances(v0.reshape(1, D), embedding, metric=metric).reshape(V)\r\n",
        "  idxs = distances.argsort()[:4]\r\n",
        "  # find the closest embedding vector in our vocabulary to V0\r\n",
        "  for idx in idxs:\r\n",
        "    word = idx2word[idx]\r\n",
        "    if word not in (w1, w2, w3): \r\n",
        "      best_word = word\r\n",
        "      break\r\n",
        "\r\n",
        "  print(w1, \"-\", w2, \"=\", best_word, \"-\", w3)\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv-1YUJDgw6U"
      },
      "source": [
        "## **Get nearset words to an input word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjbVc9oPdhKj"
      },
      "source": [
        "def nearest_neighbors(w, n=5):\r\n",
        "  if w not in word2vec:\r\n",
        "    print(\"%s not in dictionary:\" % w)\r\n",
        "    return\r\n",
        "\r\n",
        "  v = word2vec[w]\r\n",
        "  distances = pairwise_distances(v.reshape(1, D), embedding, metric=metric).reshape(V)\r\n",
        "  idxs = distances.argsort()[1:n+1]\r\n",
        "  print(\"neighbors of: %s\" % w)\r\n",
        "  for idx in idxs:\r\n",
        "    print(\"\\t%s\" % idx2word[idx])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4nqlqQnhQAr"
      },
      "source": [
        "## **Load the pre-trained word vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTXFx27PdhWx",
        "outputId": "8e31d244-d1a7-4903-e91c-6f060982ea13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\r\n",
        "print('Loading word vectors...')\r\n",
        "word2vec = {}\r\n",
        "embedding = []\r\n",
        "idx2word = []\r\n",
        "with open(\"/content/glove.6B.300d.txt\", encoding='utf-8') as f:\r\n",
        "  # is just a space-separated text file in the format:\r\n",
        "  # word vec[0] vec[1] vec[2] ...\r\n",
        "  for line in f:\r\n",
        "    values = line.split()\r\n",
        "    word = values[0]\r\n",
        "    vec = np.asarray(values[1:], dtype='float32')\r\n",
        "    word2vec[word] = vec\r\n",
        "    embedding.append(vec)\r\n",
        "    idx2word.append(word)\r\n",
        "print('Found %s word vectors.' % len(word2vec))\r\n",
        "embedding = np.array(embedding)\r\n",
        "V, D = embedding.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXaRinL7hjRn"
      },
      "source": [
        "# **Find analogies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCKbEaoadha3",
        "outputId": "8dc449a7-1066-4043-8000-beacbea97bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "find_analogies('king', 'man', 'woman')\r\n",
        "find_analogies('france', 'paris', 'london')\r\n",
        "find_analogies('france', 'paris', 'rome')\r\n",
        "find_analogies('paris', 'france', 'italy')\r\n",
        "find_analogies('france', 'french', 'english')\r\n",
        "find_analogies('japan', 'japanese', 'chinese')\r\n",
        "find_analogies('japan', 'japanese', 'italian')\r\n",
        "find_analogies('japan', 'japanese', 'australian')\r\n",
        "find_analogies('december', 'november', 'june')\r\n",
        "find_analogies('miami', 'florida', 'texas')\r\n",
        "find_analogies('einstein', 'scientist', 'painter')\r\n",
        "find_analogies('china', 'rice', 'bread')\r\n",
        "find_analogies('man', 'woman', 'she')\r\n",
        "find_analogies('man', 'woman', 'aunt')\r\n",
        "find_analogies('man', 'woman', 'sister')\r\n",
        "find_analogies('man', 'woman', 'wife')\r\n",
        "find_analogies('man', 'woman', 'actress')\r\n",
        "find_analogies('man', 'woman', 'mother')\r\n",
        "find_analogies('heir', 'heiress', 'princess')\r\n",
        "find_analogies('nephew', 'niece', 'aunt')\r\n",
        "find_analogies('france', 'paris', 'tokyo')\r\n",
        "find_analogies('france', 'paris', 'beijing')\r\n",
        "find_analogies('february', 'january', 'november')\r\n",
        "find_analogies('france', 'paris', 'rome')\r\n",
        "find_analogies('paris', 'france', 'italy')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "king - man = queen - woman\n",
            "france - paris = britain - london\n",
            "france - paris = italy - rome\n",
            "paris - france = rome - italy\n",
            "france - french = england - english\n",
            "japan - japanese = china - chinese\n",
            "japan - japanese = italy - italian\n",
            "japan - japanese = australia - australian\n",
            "december - november = april - june\n",
            "miami - florida = dallas - texas\n",
            "einstein - scientist = picasso - painter\n",
            "china - rice = chinese - bread\n",
            "man - woman = he - she\n",
            "man - woman = uncle - aunt\n",
            "man - woman = brother - sister\n",
            "man - woman = brother - wife\n",
            "man - woman = actor - actress\n",
            "man - woman = father - mother\n",
            "heir - heiress = prince - princess\n",
            "nephew - niece = uncle - aunt\n",
            "france - paris = japan - tokyo\n",
            "france - paris = china - beijing\n",
            "february - january = october - november\n",
            "france - paris = italy - rome\n",
            "paris - france = rome - italy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ93jiXghtmR"
      },
      "source": [
        "# **Find neighbors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr2z6FWfdheO",
        "outputId": "7ec76473-2bd0-40d9-ebc2-b81fabc320b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nearest_neighbors('king')\r\n",
        "nearest_neighbors('france')\r\n",
        "nearest_neighbors('japan')\r\n",
        "nearest_neighbors('einstein')\r\n",
        "nearest_neighbors('woman')\r\n",
        "nearest_neighbors('nephew')\r\n",
        "nearest_neighbors('february')\r\n",
        "nearest_neighbors('rome')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neighbors of: king\n",
            "\tqueen\n",
            "\tprince\n",
            "\tmonarch\n",
            "\tkingdom\n",
            "\tthrone\n",
            "neighbors of: france\n",
            "\tfrench\n",
            "\tparis\n",
            "\tbelgium\n",
            "\tspain\n",
            "\titaly\n",
            "neighbors of: japan\n",
            "\tjapanese\n",
            "\ttokyo\n",
            "\tkorea\n",
            "\tchina\n",
            "\tasia\n",
            "neighbors of: einstein\n",
            "\trelativity\n",
            "\tbohr\n",
            "\tphysicists\n",
            "\theisenberg\n",
            "\tsigmund\n",
            "neighbors of: woman\n",
            "\tgirl\n",
            "\tman\n",
            "\tmother\n",
            "\tshe\n",
            "\ther\n",
            "neighbors of: nephew\n",
            "\tbrother\n",
            "\tcousin\n",
            "\tgrandson\n",
            "\tuncle\n",
            "\tson\n",
            "neighbors of: february\n",
            "\toctober\n",
            "\tdecember\n",
            "\tjanuary\n",
            "\tnovember\n",
            "\tapril\n",
            "neighbors of: rome\n",
            "\titaly\n",
            "\tnaples\n",
            "\tturin\n",
            "\tvenice\n",
            "\troman\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}